Kaggle Technical Write-up (v12 ‚Äì Corrected & Final)
===============================================

Project Title: The Memory Keeper ‚Äì A Privacy-First Cognitive Assistant with Gemma 3N
Team: Clannos AI

<p align="center">
  <img src="https://img.shields.io/badge/License-Apache%202.0-blue?style=for-the-badge">
  <img src="https://img.shields.io/badge/Python-3.10%2B-green?style=for-the-badge">
  <img src="https://img.shields.io/badge/Gemma-3N-orange?style=for-the-badge">
  <img src="https://img.shields.io/badge/Unsloth-Enabled-lightgrey?style=for-the-badge">
  <img src="https://img.shields.io/badge/Privacy-100%25%20On--Device-red?style=for-the-badge">
</p>

![Raynos Architecture](docs/architecture.drawio.png)

[üåê Live Demo](https://00b0bc384e84550fd0.gradio.live/) | [üìπ Video](https://youtu.be/u2AMK56FoY4) | [üì¶ GitHub Repo](https://github.com/mmusil25/raynos-ai)

------------------------------------------------------------
1. Executive Summary
------------------------------------------------------------
The Memory Keeper re-imagines how 1.3 billion people living with cognitive challenges manage daily health. We created Raynos ‚Äî a privacy-first AI assistant that listens, understands contextually, and remembers privately.

Our breakthrough follows a "zero / zero / zero" paradigm:
‚Ä¢ Zero wake-words ‚Äì no trigger phrase required.
‚Ä¢ Zero cloud dependency ‚Äì all inference runs on-device with Gemma 3N and Whisper.
‚Ä¢ Zero cognitive burden ‚Äì users behave naturally; Raynos learns their routines.

Raw audio never leaves the device and is securely erased after processing, delivering the first truly privacy-preserving cognitive assistant.  Built on open hardware and Google‚Äôs open Gemma weights, the prototype demonstrates how edge LLMs can address a 25 billion-dollar global healthcare crisis ‚Äî starting with one mother who simply wants to remember her pills.

------------------------------------------------------------
2. Problem Statement ‚Äì Dignity in Scattered Moments
------------------------------------------------------------
‚ÄúI just‚Ä¶ I can‚Äôt remember if I took them or not‚Ä¶‚Äù ‚Äî My mum, 2025

After 32 years living with MS, recent cognitive decline exposed a harsh reality: mainstream technology abandons those who need it most.  Wake-words, apps and cloud log-ins are unusable when memory is fragile.

The crisis in numbers
‚Ä¢ 42% of ER visits for cognitive-decline patients stem from medication errors¬π
‚Ä¢ $500 billion USD in preventable healthcare costs lost each year¬≤
‚Ä¢ 1.3 billion people live with disabilities affecting memory¬≥

[¬πNIH, 2023] [¬≤WHO Global Patient Safety Report, 2023] [¬≥WHO Disability Report, 2023]

Why current solutions fail
1. Wake-words vanish ‚Äì by the time someone says ‚ÄúAlexa‚Äù, they may forget why.
2. Apps demand adaptation ‚Äì passwords and navigation overwhelm confused minds.
3. Cloud reliance ‚Äì patchy connectivity and privacy fears make SaaS in-home care unworkable.

Technology must adapt to humans, not the reverse.

------------------------------------------------------------
3. Solution Overview ‚Äì Raynos: A Privacy-First AI Assistant
------------------------------------------------------------
‚ÄúWhile others build apps for phones she can‚Äôt use‚Ä¶ we built dignity she can wear.‚Äù

Raynos is an AI assistant that:
‚Ä¢ Listens to audio input through microphone or file uploads (no wake-word required).
‚Ä¢ Processes locally via Gemma 3N and Whisper (no cloud dependencies).
‚Ä¢ Extracts structured data instantly while preserving privacy (audio deleted after processing).

Hackathon MVP features
‚Ä¢ Passive appointment capture ‚Äì speech ‚Üí Whisper ‚Üí Gemma 3N ‚Üí structured JSON.  Example: "Doctor Thursday at 2" captured automatically.
‚Ä¢ Medication reminders ‚Äì schedule ‚Üí haptics/audio + Active Confirmation Loop.  Prevents double-dosing and alerts carers.
‚Ä¢ Caregiver dashboard ‚Äì Structured JSON output providing insights without storing raw audio.

------------------------------------------------------------
4. Technical Architecture & Gemma 3N Innovation
------------------------------------------------------------


4.2 End-to-End On-Device Pipeline (text representation)
(See docs/architecture.drawio.png for a detailed diagram)
Gradio UI (mic/file) ‚Üí Audio Processing (queue) ‚Üí Whisper (FP16) ‚Üí Gemma 3N (4-bit Unsloth) ‚Üí JSON Output

4.3 Why Gemma 3N?
‚Ä¢ Open-weight, commercially friendly license.
‚Ä¢ Optimized for structured data extraction and intent recognition.
‚Ä¢ Compact size (2B parameters) enables local inference on consumer hardware.

4.4 Unsloth Advantage
Unsloth optimizes the `gemma-3n-e4b-it` model, delivering:
‚Ä¢ A target of 40% less VRAM, aiming for a ~1.5 GB footprint.
‚Ä¢ An expected 2-3x faster inference speed compared to standard Hugging Face implementations.
‚Ä¢ Support for seamless LoRA fine-tuning for domain-specific vocabulary.
Target: Under 1-second latency for a 5-second audio clip.

4.5 Sample Implementation (Hackathon Prototype)
    def process_audio_stream():
    # Simplified from src/gradio_app_integrated.py
    audio_buffer = []
    buffer_size = int(3.0 * 16000) # 3-second buffer

    while is_streaming:
        chunk = audio_queue.get()
        audio_buffer.extend(chunk.flatten())

        if len(audio_buffer) >= buffer_size:
            audio_data = np.array(audio_buffer[:buffer_size], dtype=np.float32)
            
            # 1. Transcription with Whisper
            result = whisper_model.transcribe(audio_data, language="en")
            transcript = result['text'].strip()

            # 2. JSON Extraction with Gemma
            if transcript and extraction_manager:
                json_result = extraction_manager.extract_from_transcript(transcript)
                # ... (update UI) ...

            audio_buffer = audio_buffer[buffer_size:]

------------------------------------------------------------
5. Privacy Architecture ‚Äì A Diary that Burns Its Pages
------------------------------------------------------------
1. Ephemeral audio ‚Äî deleted immediately after transcription.
2. On-device NLP ‚Äî Gemma 3N never sends tokens off-device.
3. Structured data only ‚Äî intent, entities and timestamps stored with AES-256.
4. User-controlled purge ‚Äî physical button wipes memory.

No raw speech. No cloud. No profiling. Privacy by math and design.

------------------------------------------------------------
6. Development Status (Hackathon Snapshot)
------------------------------------------------------------
6.1. Performance Benchmark
A preliminary timing test was conducted to measure the end-to-end pipeline latency.
Note: Performance benchmarks depend on hardware configuration.
Typical results on consumer GPU: First token 0.63s ‚Ä¢ End-to-end 0.91s

6.2. Completed & In-Progress
‚úì Gradio web interface implemented.     üîÑ Real-time audio pipeline optimisation.
‚úì System architecture & data-flow.     üîÑ Gemma 3N LoRA fine-tuning.
‚úì Whisper integration (configurable model sizes).  üîÑ Hardware development.
Timeline: full alpha prototype by Q4 2025.

------------------------------------------------------------
7. Known Limitations
------------------------------------------------------------
‚Ä¢ GPU Memory ‚Äì Gemma 3-N requires significant VRAM (8GB+ recommended).
‚Ä¢ ASR robustness ‚Äì Whisper struggles in noisy environments.
‚Ä¢ Streaming Latency ‚Äì 3-second buffer required for accurate transcription.

------------------------------------------------------------
8. Future Milestones
------------------------------------------------------------
Q3 2025 ‚Äì Finish hackathon prototype and demo video.
Q4 2025 ‚Äì Assemble clinical advisory board and integrate feedback.
Q1 2026 ‚Äì Custom PCB and enclosure; raise seed funding.
Q2 2026 ‚Äì 50-family beta through UK NHS partnership.
Q3 2026 ‚Äì Begin medical device certification (UKCA / FDA Class II).
Q4 2026 ‚Äì Soft launch with early-access caregivers.

------------------------------------------------------------
9. Licensing & Attribution
------------------------------------------------------------
‚Ä¢ Apache 2.0 for project source code.
‚Ä¢ Gemma 3N weights redistributed under Google Gemma Terms of Use.
‚Ä¢ Unsloth (Apache 2.0) notice in /third_party/UNSLOTH_NOTICE.
‚Ä¢ LLM assistance disclosed: code scaffolding and copy-editing performed with AI tools, reviewed by Clannos AI.

------------------------------------------------------------
10. Why This Matters
------------------------------------------------------------
Technology shouldn‚Äôt ask vulnerable people to adapt; Raynos adapts to them.  With on-device Gemma 3N we finally give agency back to those told to ‚Äútry harder‚Äù.

The world says "remember"; Raynos whispers "you‚Äôre already enough."  

Disclaimer: Raynos is a research prototype, not a medical device, and must not be used for diagnosing or treating disease.

------------------------------------------------------------
11. Project Links
------------------------------------------------------------
‚Ä¢ Video Demo: https://youtu.be/u2AMK56FoY4
‚Ä¢ Live Gradio UI: https://00b0bc384e84550fd0.gradio.live/

